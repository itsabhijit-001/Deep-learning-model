{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style=\"background-color:red;font-family:newtimeroman;font-size:550%;text-align:center;border-radius: 15px 50px;padding: 5px\">Corona Tweet Analysis</h1>\n","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"background-color:skyblue;font-family:newtimeroman;font-size:550%;text-align:center;border-radius: 15px 50px;padding: 5px\">Importing Library and Data</h1>\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport nltk\nimport re\nfrom nltk.corpus import stopwords\nfrom tqdm import tqdm\nfrom nltk.stem import WordNetLemmatizer\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport warnings\nimport keras\nfrom keras.layers import Dense,LSTM,Embedding,Input,GlobalMaxPool1D\nfrom keras.models import Sequential\nfrom sklearn.naive_bayes import CategoricalNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nwarnings.filterwarnings('ignore')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv('../input/covid-19-nlp-text-classification/Corona_NLP_train.csv',encoding='latin1',parse_dates=['TweetAt'])\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe(include='O')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.Sentiment.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## There is very high probability that 'Extremely postivie' or 'Extremely Negative' would be mispredicted as 'Postive' or 'Negative', or vice-versa. Because words used in those tweets are very much similiar to each other. So in order to avoid these types of confusion we could assign them same.","metadata":{}},{"cell_type":"code","source":"data.Sentiment=data.Sentiment.replace({'Extremely Positive':'Positive','Extremely Negative':'Negative'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_text,val_text,train_label,val_label=train_test_split(data.OriginalTweet,data.Sentiment,\n                                                             test_size=0.15,random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lbl_encoder=LabelEncoder()\ntrain_label_codes=lbl_encoder.fit_transform(train_label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lbl_encoder.classes_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Lemmatizer(object):\n    def __init__(self):\n        self.lemmatizer = WordNetLemmatizer()\n    def __call__(self, sentence):\n        sentence=re.sub('(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)',' ',sentence)\n        sentence=re.sub('[^0-9a-z]',' ',sentence)\n        return [self.lemmatizer.lemmatize(word) for word in sentence.split() if len(word)>1]","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:skyblue;font-family:newtimeroman;font-size:550%;text-align:center;border-radius: 15px 50px;padding: 5px\">Two Processes to predict our required classes</h1>\n","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"background-color:lightgreen;font-family:newtimeroman;font-size:550%;text-align:center;border-radius: 15px 50px;padding: 5px\">Process 1</h1>\n","metadata":{}},{"cell_type":"code","source":"tokenizer=CountVectorizer(max_features=5000,stop_words='english',lowercase=True,tokenizer=Lemmatizer())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x=tokenizer.fit_transform(train_text).toarray()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.get_params()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_names=tokenizer.get_feature_names()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_x=tokenizer.transform(val_text).toarray()\nval_label_codes=lbl_encoder.transform(val_label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nmodel_p1=LogisticRegression()\nmodel_p1.fit(train_x,train_label_codes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Validation classification report',classification_report(val_label_codes,model_p1.predict(val_x)))\nprint('Training classification report',classification_report(train_label_codes,model_p1.predict(train_x)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:skyblue;font-family:newtimeroman;font-size:550%;text-align:center;border-radius: 15px 50px;padding: 5px\">Data Visualization</h1>","metadata":{}},{"cell_type":"code","source":"data.Sentiment=lbl_encoder.transform(data.Sentiment)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=data.set_index('TweetAt').resample('W').count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\ndf['OriginalTweet'].plot()\nplt.title('Number of Tweet on Weekly basis in year 2020',fontdict={'size':'20'})\nplt.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nplt.pie(train_label.value_counts(),explode=[0.01,0.01,0.001],colors=['green','red','blue'],\n        labels=['Positive','Negative','Neutral'],autopct='%0.2f%%',radius=1,startangle=45)\nplt.title('Sentiments',fontdict={'size':'20'})\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"twitter_mask=np.array(Image.open('../input/corona-virus/twitter.png'))\nwc=WordCloud(max_words=300,mask=twitter_mask,background_color='white')\nwc.generate(' '.join(word for word in feature_names[1500:3500] ))\nplt.figure(figsize=(20,15))\nplt.axis('off')\nplt.imshow(wc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corona_mask=np.array(Image.open('../input/corona-virus/coronav.jpg'))\nwc_corona=WordCloud(max_words=300,mask=corona_mask,background_color='white')\nwc_corona.generate(' '.join(word for word in feature_names[3500:] ))\nplt.figure(figsize=(20,15))\nplt.axis('off')\nplt.imshow(wc_corona)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:lightgreen;font-family:newtimeroman;font-size:550%;text-align:center;border-radius: 15px 50px;padding: 5px\">Process 2</h1>\n","metadata":{}},{"cell_type":"code","source":"early_stop=EarlyStopping(monitor='val_accuracy',patience=3)\nreduceLR=ReduceLROnPlateau(monitor='val_accuarcy',patience=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"token=Tokenizer(num_words=5000,oov_token=Lemmatizer())\ntoken.fit_on_texts(train_text)\ntrain_x_2=token.texts_to_sequences(train_text)\ntrain_x_2=pad_sequences(train_x_2,maxlen=60,padding='post',truncating='post')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_x_2=token.texts_to_sequences(val_text)\nval_x_2=pad_sequences(val_x_2,maxlen=60,padding='post',truncating='post')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_dimension=32\nv=len(token.word_index)\nmodel=Sequential()\nmodel.add(Input(shape=(60,)))\nmodel.add(Embedding(v+1,embedding_dimension))\n# model.add(Input(shape=(train_x.shape[1],)))\nmodel.add(LSTM(64,return_sequences=True))\n# model.add(Dense(128))\nmodel.add(GlobalMaxPool1D())\nmodel.add(Dense(64))\nmodel.add(Dense(3,activation='softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\nr=model.fit(train_x_2,train_label_codes,validation_data=(val_x_2,val_label_codes),\n            epochs=20,batch_size=50,callbacks=[reduceLR,early_stop])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['loss'])\nplt.plot(r.history['val_loss'])\nplt.title('LOSS',fontdict={'size':'22'})\nplt.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(r.history['accuracy'])\nplt.plot(r.history['val_accuracy'])\nplt.title('Accuracy',fontdict={'size':'22'})\nplt.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:lightblue;font-family:newtimeroman;font-size:550%;text-align:center;border-radius: 15px 50px;padding: 5px\">Predicting on test dataset</h1>\n","metadata":{}},{"cell_type":"code","source":"test_data=pd.read_csv('../input/covid-19-nlp-text-classification/Corona_NLP_test.csv',encoding='latin1')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data['Sentiment']=test_data['Sentiment'].replace({'Extremely Positive':'Positive','Extremely Negative':'Negative'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_label=lbl_encoder.transform(test_data['Sentiment'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_x=test_data.OriginalTweet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:lightgreen;font-family:newtimeroman;font-size:550%;text-align:center;border-radius: 15px 50px;padding: 5px\">By Process 1</h1>\n","metadata":{}},{"cell_type":"code","source":"test_x_1=tokenizer.transform(test_x).toarray()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(test_label,model_p1.predict(test_x_1)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:lightgreen;font-family:newtimeroman;font-size:550%;text-align:center;border-radius: 15px 50px;padding: 5px\">By Process 2</h1>\n","metadata":{}},{"cell_type":"code","source":"test_x_2=token.texts_to_sequences(test_data['OriginalTweet'])\ntest_x_2=pad_sequences(test_x_2,maxlen=60,padding='post',truncating='post')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(test_label,model.predict_classes(test_x_2)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:lightblue;font-family:newtimeroman;font-size:550%;text-align:center;border-radius: 15px 50px;padding: 5px\">Conclusion</h1>\n","metadata":{}},{"cell_type":"markdown","source":"## Here both processes worked quite well though LSTM model worked better than linear model as Sequencial model understands data more efficiently and sequencially but that's not the case with linear model it just studies some common words and predict its output accordingly. So to use in daily practice for NLP Sequential model is mostly prefered.","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"background-color:pink;font-family:newtimeroman;font-size:550%;text-align:center;border-radius: 15px 10px;padding: 5px\">If you liked this notebook . please upvote !!!</h1>\n","metadata":{}}]}